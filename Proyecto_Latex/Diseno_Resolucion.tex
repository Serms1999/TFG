%!TEX root = TFG.tex

\chapter{Diseño y resolución} \label{chap:diseno}

En este capítulo se realiza la descripción de los experimentos realizados, su análisis y la búsqueda de un modelo de Machine Learning, así como los resultados finales del trabajo.

En este trabajo se usará una topología de red como la que ilustra la Fig. \ref{fig:top}. En dicha topología se puede ver que tenemos un observador (modelo RockPro64) y 5 dispositivos a analizar (Raspberry Pi 4 Model B).

\begin{figure}[htpb!]
    \centering
    \resizebox{0.7\textwidth}{!}{
        \input{topologia}
    }
    \caption{Topología de la red}
    \label{fig:top}
\end{figure}

La idea es enviar mensajes desde el observador a cada uno de los dispositivos y que cada uno de los dispositivos responda a esos mensajes, obteniendo así una marca de tiempo de ese dispositivo.

\section{Arquitectura propuesta}

En este trabajo ha sido propuesta una arquitectura en la que se basará todo el desarrollo del mismo. Esta arquitectura se puede ver en la Fig. \ref{fig:architecture}.

\begin{figure}
    \centering
    \input{architecture_scheme}
    \caption{Arquitectura propuesta}
    \label{fig:architecture}
\end{figure}

En esta arquitectura se compone de dos partes. Por una parte, los dispositivos que generan y comparten los datos, y por otra parte el dispositivo externo que se encarga de tanto de analizar y procesar los datos, como de ajustar los algoritmos de Machine Learning que se usan. Este dispositivo también es el encargado de evaluar los resultados que obtienen los modelos ya entrenados y compararlos entre ellos. A continuación se explicarán cada una de estas partes.

\begin{enumerate}[label=\textbf{\Alph*}:]
    \item en esta parte se preparan los dispositivos para la recolección de las muestras. Se establecen frecuencias de CPU fijas, para evitar que esto afecte a los ciclos del procesador. También se deshabilita el servicio \acrshort{ntp} que modifica el reloj interno del dispositivo.
    \item en esta parte se obtienen los datos de los distintos dispositivos que van a ser analizados. Cada segundo estos dispositivos obtienen el valor de su reloj interno y lo envían al cliente. Este proceso se repite durante la obtención de toda la muestra, que debe de ser un periodo de tiempo suficientemente largo.
    \item en esta parte el cliente obtiene cada una de las marcas de tiempo de los dispositivos. Con estos valores calcula el incremento entre cada par de marcas de un dispositivo y con ello construye un conjunto de datos. Sobre este conjunto de datos, y mediante el uso de una ventana deslizante, se obtienen diversos valores estadísticos que serán representativos de la ventana en cuestión. Algunos de estos valores pueden presentar correlación entre sí, por ello, se obviarán todos excepto uno que servirá de representante.
    \item en esta parte se seleccionan los distintos algoritmos de Machine Learning que se usarán en este trabajo. En este proyecto se ha optado por usar algoritmos de aprendizaje supervisado orientados a clasificación, y algoritmos de aprendizaje no supervisado orientados a la detección de anomalías. Una vez se sabe cuales serán los algoritmos a usar, se procede a ajustar sus hiperparámetros con el objetivo de hacer que los modelos resultantes se ajusten de la mejor manera posible a los datos de este trabajo.
    \item en esta parte se eligen las métricas que se van a usar para comparar los distintos modelos entre sí. Se seleccionan métricas distintas para comparar los algoritmos de clasificación y los de detección de anomalías. Se obtienen los resultados de las métricas deseadas para cada uno de los modelos entrenados, y una vez se está en posesión de todas ellas se procede a comparar los modelos entre sí.
\end{enumerate}

\section{Elección del protocolo}

Las opciones barajadas han sido \acrfull{tcp} e \acrfull{icmp}. En un principio se pensaba usar las marcas de tiempo contenidas en las cabeceras de estos protocolos, pero esta idea se descartó puesto que únicamente permitían obtener los tiempos en milisegundos. El objetivo era obtener los tiempos en nanosegundos por tanto, se enviaron los datos en el cuerpo del paquete que no tiene una limitación tan corta de espacio. 

Con el fin de mantener la conexión persistente en toda la muestra se escogió el protocolo \acrshort{tcp}, ya que una vez establecida la conexión se mantendrá hasta el final.

\section{Obtención de datos}

Para obtener los datos se usará una estructura cliente-servidor. Los dispositivos a analizar serán los que tomen el rol de servidores y el observador será el cliente.

Con esta idea en mente se crea un programa servidor que escuche a cualquier dirección IP en un determinado puerto y responda con una marca de tiempo en nanosegundos. Este programa se ejecutará en cada uno de los dispositivos bajo análisis.

A la hora de capturar los datos se usó un reloj interno que no debería sufrir alteraciones que disminuyeran su valor (\texttt{steady\_clock}\cite{steadyclockcpp}).

Una vez los dispositivos estén todos escuchando, el observador ejecutará un programa cliente que es el que se encargará de enviar los mensajes al servidor correspondiente. Este programa guarda una marca de tiempo al comienzo de la ejecución $t_{start}$, que será nuestro punto de referencia. Después mandará $n$ mensajes equiespaciados en intervalos de 1 segundo.

En cada ejecución del bucle se obtendrá una marca de tiempo en el observador $t_i$, y una marca de tiempo del dispositivo $t'_i$. Con esto se consiguen tener varios datos:
\begin{itemize}
    \item La marca de tiempo relativa a cada mensaje desde el inicio, $t_i - t_{start}$. Teóricamente debería de dar valores exactos, ya que se manda un mensaje cada segundo, pero existe cierto retraso.
    \item La marca de tiempo absoluta del observador $t_i$.
    \item La marca de tiempo absoluta del dispositivo $t'_i$.
    \item La desviación del reloj del dispositivo respecto al del observador, $t_i - t'_i$.
\end{itemize}

Un ejemplo de cómo se guardan estos datos se puede ver en la Tabla \ref{tab:trace_example}.
\begin{table}[htpb!]
    \centering
    \resizebox{0.75\textwidth}{!}{
    \begin{tabular}{ccccc}
        \toprule
        \texttt{time} & \texttt{TSrock} & \texttt{TSrasp} & \texttt{offset} & \texttt{device} \\
        \midrule
        292 & 119238112796030 & 104592709716803 & -14645403079227 & 192.168.1.111 \\
        1001191222 & 119239113986960 & 104593710167425 & -14645403819535 & 192.168.1.111 \\
        2001485862 & 119240114281600 & 104594710453699 & -14645403827901 & 192.168.1.111 \\
        \vdots & \vdots & \vdots & \vdots & \vdots \\
        \bottomrule
    \end{tabular}
    }
    \caption{Ejemplo de los datos obtenidos de cada dispositivo}
    \label{tab:trace_example}
\end{table}

Este proceso se realizará para cada dispositivo tanto en una muestra secuencial, como en una muestra en paralelo. 


\section{Análisis de los datos}

En esta sección se estudiará el incremento de la desviación del reloj en cada una de las muestras, así como la desviación acumulada en cada punto.

\subsection{Experimento 1: Muestra secuencial}

En este primer experimento se ha tomado una muestra de \SI{7200}{} segundos, es decir, \SI{2}{} horas por dispositivo, lo que en total suman \SI{10}{} horas de muestras.

En la Fig. \ref{fig:off_acu_secuencial} se muestra la desviación (offset) acumulada en cada dispositivo durante esas \SI{2}{} horas.

\begin{figure}[htpb!]
    \centering
    \includegraphics[scale=0.65]{../Python/plots/individual/offset_plot}
    \caption{Offset acumulado muestra secuencial}
    \label{fig:off_acu_secuencial}
\end{figure}

Como se puede ver hay 2 tipos de comportamiento. Los dispositivos 1, 2 y 3 se mantienen monótonos al comienzo para después incrementar mucho su desviación. Por contra los dispositivos 4 y 5 se mantienen sin grandes cambios en toda la muestra. Esto se puede ver más claramente en la Fig. \ref{fig:off_acu_secuencial_diffs}.

\begin{figure}[htpb!]
    \centering
    \subfloat[Dispositivos 1, 2 y 3]{\includegraphics[width=0.4\textwidth]{../Python/plots/individual/offset_plot_123}}
    \quad
    \subfloat[Dispositivos 4 y 5]{\includegraphics[width=0.4\textwidth]{../Python/plots/individual/offset_plot_45}}
    \caption{Diferencias entre offsets de dispositivos}
    \label{fig:off_acu_secuencial_diffs}
\end{figure}

Lo que interesa al final es obtener una forma de distinguir estadísticamente los datos, para ello se genera un gráfico que muestre entre que valores se mueven estos datos en cada dispositivo, en definitiva, se puede ver con un diagrama de cajas (Fig. \ref{fig:box_secuencial}). Se han eliminado los valores atípicos ya que a tan pequeña escala no dejan ver los verdaderos resultados.

\begin{figure}[htpb!]
    \centering
    \includegraphics{../Python/plots/individual/boxplot_no_out}
    \caption{Diagrama de cajas muestra secuencial}
    \label{fig:box_secuencial}
\end{figure}

Este diagrama ilustra lo comentado anteriormente. Los dispositivos 4 y 5 son los que menos varían, esto se puede ver en que las cajas son pequeñas y la mediana está centrada entre los cuartiles (Q1 y Q3). 

En los otros 3 dispositivos se observa como entre la mediana y el tercer cuartil hay más espacio que entre la mediana y el primer cuartil. Esto se debe a que tienen muchos incrementos grandes, por eso crecen tan bruscamente.

Con esto se tiene una idea de los dispositivos son distinguibles estadísticamente, lo que confirma que se podrá entrenar un modelo que los identifique.

\iffalse
Por último se obtienen las variables estadísticas que podrán ser usadas para entrenar los modelos (Tabla \ref{tab:stats_sec}). 

\begin{table}
    \centering
    \resizebox{0.85\textwidth}{!}{
        \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c}
             & Sum & Mean & Median & Mode & Std & IQR & Kurtosis & Skew & Max & Min & Device \\
             \hline\hline
            1 & 161935.0 & 2698.9166666666665 & 2368.0 & -10638.0 & 4811.992019561929 & 4723.75 & 1.9261137847830017 & 0.393744697396757 & 16643.0 & -10638.0 & Disp. 1 \\
            2 & -133618.0 & -2226.9666666666667 & -2069.0 & -14962.0 & 4940.972387543091 & 3037.75 & 3.06918010272503 & 0.3990191392522864 & 12839.0 & -14962.0 & Disp. 2 \\
            3 & -474582.0 & -7909.7 & -8169.5 & -21129.0 & 4835.756096735922 & 4555.0 & 3.6509891533583105 & 0.7015937932968024 & 10047.0 & -21129.0 & Disp. 3 \\
            4 & 38723.0 & 645.3833333333333 & 343.5 & -511.0 & 2546.367949044463 & 2792.25 & 1.237821148508425 & 0.6920187401340381 & 8323.0 & -4649.0 & Disp. 4 \\
            5 & 18048.0 & 300.8 & 221.5 & -8231.0 & 3895.818561535789 & 4542.0 & 0.10736681592393049 & 0.13881288039853917 & 9109.0 & -8231.0 & Disp. 5 \\
            6 & 155944.0 & 2599.0666666666666 & 2368.0 & -10638.0 & 4960.2799021168785 & 4723.75 & 1.6897518199182318 & 0.28091999994143674 & 16643.0 & -10638.0 & Disp. 1 \\
            \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
        \end{tabular}
    }
    \caption{Datos estadísticos muestra secuencial}
    \label{tab:stats_sec}
\end{table}
\fi


\subsection{Experimento 2: Muestra paralela}

Para el segundo experimento se han capturado datos de todos los dispositivos simultáneamente durante un periodo de \SI{43200}{} segundos, es decir, \SI{12}{} horas.

La Fig. \ref{fig:off_acu_paralelo} muestra la desviación acumulada en cada dispositivo en este periodo de tiempo. En este gráfico también se han marcado ciertos puntos en los que los dispositivos parecen ``sincronizarse''. Con esto nos referimos a que alrededor de estas marcas de tiempo todos los dispositivos cambian de tendencia bruscamente y además parecen repetirse con cierta periodicidad. Las marcas de tiempo de este gráfico corresponden a los puntos $\{\SI{4000}{},  \SI{16500}{}, \SI{29000}{}, \SI{41000}{}\}$ que están aproximadamente equidistantes (aproximadamente \SI{12000}{} segundos).

\begin{figure}[htpb!]
    \centering
    \includegraphics{../Python/plots/parallel/offset_plot}
    \caption{Offset acumulado muestra paralela}
    \label{fig:off_acu_paralelo}
\end{figure}

Esta ``sincronización'' entre dispositivos parece deberse a algún tipo de actualización del reloj interno del dispositivo mediante algún demonio del sistema operativo. El principal demonio que se encarga de esta tarea es el servicio NTP, el cual fue desactivado para realizar estas pruebas. 

Consultando otro diagrama de cajas con el incremento de la desviación en cada instante (Fig. \ref{fig:box_paralelo}) se observa como todos los dispositivos están más a la par que en la muestra secuencial (Fig. \ref{fig:box_secuencial}). Aún así, siguen teniendo ciertas diferencias, con lo que se puede concluir que también son estadísticamente diferenciables.

\begin{figure}[htpb!]
    \centering
    \includegraphics{../Python/plots/parallel/boxplot_no_out}
    \caption{Diagrama de cajas muestra paralela}
    \label{fig:box_paralelo}
\end{figure}

\subsection{Elección de la muestra de datos}

Analizando los incrementos de la desviación en ambas muestras (Fig. \ref{fig:box_secuencial} y \ref{fig:box_paralelo}) se puede ver que la muestra paralela tiene valores más parecidos a los esperados. Estos valores de incremento de la desviación son más pequeños y más parecidos entre todos los dispositivos, es por ello que se entrenarán los algoritmos con los datos de la muestra paralela.

\section{Preprocesamiento de los datos}

En esta sección se realizará un preprocesamiento de los datos para su adecuación de cara al entrenamiento de los modelos de Machine Learning. se obtendrán diversas variables estadísticas de estos datos, y a continuación, se eliminarán las variables estadísticas que se encuentren correlacionadas.

Estas variables se obtendrán mediante el uso de una ventana deslizante de \SI{1}{} minuto sobre el incremento de la desviación del reloj del dispositivo.

Una ventana deslizante es una forma de agrupar datos consecutivos mientras se recorre una colección. Un ejemplo de ventana deslizante se puede ver en la Fig. \ref{fig:ex_sliding_window}.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c}
        \hline
        $\cdots$ & $x_{i-2}$ & $x_{i-1}$ & $x_{i}$ & $x_{i+1}$ & $x_{i-2}$ & $\cdots$ \\
        \hline
        \multicolumn{2}{c}{} & \multicolumn{3}{c}{\upbracefill} & \multicolumn{2}{c}{} \\[-1ex]
        \multicolumn{2}{c}{} & \multicolumn{3}{c}{\scriptsize ventana} & \multicolumn{2}{c}{} \\
    \end{tabular}
    \phantom{}\\
    \vspace{0.5cm}
    \begin{tabular}{c|c|c|c|c|c|c}
        \hline
        $\cdots$ & $x_{i-2}$ & $x_{i-1}$ & $x_{i}$ & $x_{i+1}$ & $x_{i-2}$ & $\cdots$ \\
        \hline
        \multicolumn{3}{c}{} & \multicolumn{3}{c}{\upbracefill} & \multicolumn{1}{c}{} \\[-1ex]
        \multicolumn{3}{c}{} & \multicolumn{3}{c}{\scriptsize ventana} & \multicolumn{1}{c}{} \\
    \end{tabular}
    \caption{Ejemplo de una ventana deslizante}
    \label{fig:ex_sliding_window}
\end{figure}

Las variables estadísticas que se obtendrán de los datos de la muestra paralela serán:
\begin{multicols}{2}
    \begin{itemize}
        \item Suma
        \item Media
        \item Mediana
        \item Moda
        \item Desviación típica
        \item Rango intercuartílico
        \item Curtosis
        \item Coeficiente de asimetría (skewness)
        \item Máximo
        \item Mínimo
    \end{itemize}
\end{multicols}

\iffalse
\subsection{Detección de anomalías}

En esta sección se buscarán valores que sean atípicos en las muestras de los distintos dispositivos. Se usará para ello el incremento de la desviación entre muestras. 

Lo primero a realizar será seleccionar un algoritmo de detección de anomalías. En este trabajo se ha optado por \texttt{IsolationForest}, en concreto, la implementación de la librería \texttt{scikit-learn} \cite{scikitisolation}.

Una vez seleccionado el algoritmo, se le suministran los datos vistos en la sección anterior para que seleccione aquellos que considere como anómalos. Los valores seleccionados por este algoritmo serán descartados de la muestra.

Como parámetro para el algoritmo, se ha indicado un valor de contaminación de valores atípicos (\texttt{contamination}) del \SI{5}{\percent}. Este valor ha sido obtenido en base a la experimentación con distintos valores y a criterio propio.

Los resultados obtenidos se pueden ver en la Fig. \ref{fig:anomaly}. En ella se observa como los datos presentaban mucha variabilidad, a pesar de que deberían ser prácticamente constantes. Con este primer procesado se consigue eliminar estos valores no deseados.

\begin{figure}[htpb!]
    \centering
    \resizebox{0.95\textwidth}{!}{
    \begin{minipage}{0.9\textwidth}
        \centering
        \subfloat[Outliers Disp. 1]{\includegraphics[width=0.3\textwidth]{../Python/plots/parallel/delta_offset_plot_disp1.pdf}}
        \subfloat[Outliers Disp. 2]{\includegraphics[width=0.3\textwidth]{../Python/plots/parallel/delta_offset_plot_disp2.pdf}}
        \subfloat[Outliers Disp. 3]{\includegraphics[width=0.3\textwidth]{../Python/plots/parallel/delta_offset_plot_disp3.pdf}} \\
        \subfloat[Outliers Disp. 4]{\includegraphics[width=0.3\textwidth]{../Python/plots/parallel/delta_offset_plot_disp4.pdf}}
        \subfloat[Outliers Disp. 5]{\includegraphics[width=0.3\textwidth]{../Python/plots/parallel/delta_offset_plot_disp5.pdf}}
    \end{minipage}
    \begin{minipage}{0.09\textwidth}
        \subfloat{\includegraphics[scale=0.9]{../Python/plots/parallel/anomaly_legend.pdf}}
    \end{minipage}
    }
    \caption{Valores anómalos detectados}
    \label{fig:anomaly}
\end{figure}
\fi

\subsection{Obtención de las variables estadísticas}

En esta sección se generarán los datos estadísticos de la muestra paralela mediante la ventana deslizante, se obtienen los resultados que se pueden ver en la Tabla \ref{tab:stats_par}.

\begin{table}[htpb!]
    \centering
    \resizebox{0.85\textwidth}{!}{
        \begin{tabular}{cccccccccccc}
            \toprule
             & Sum & Mean & Median & Mode & Std & IQR & Kurtosis & Skew & Max & Min & Device \\
            \midrule
            1 & -284.0 & -4.733333333333333 & -203.0 & -10750.0 & 6531.321744049499 & 8739.5 & -0.8026364427898236 & 0.266444555013173 & 12077.0 & -10750.0 & Disp. 1 \\
            2 & -65895.0 & -1098.25 & 106.5 & -13344.0 & 3926.559099283938 & 2519.75 & 1.4605213340303709 & -1.1040127142547507 & 7616.0 & -13344.0 & Disp. 2 \\
            3 & 96179.0 & 1602.9833333333333 & 815.0 & -8136.0 & 5010.092595279735 & 6575.5 & -0.39715065367509084 & 0.2484646585713819 & 12831.0 & -8136.0 & Disp. 3 \\
            4 & 109162.0 & 1819.3666666666666 & 2016.5 & -10485.0 & 6159.084454763058 & 8290.5 & -0.7264084617343212 & -0.3858981208999922 & 11469.0 & -10485.0 & Disp. 4 \\
            5 & -81317.0 & -1355.2833333333333 & -2127.0 & -6378.0 & 3665.051390911538 & 2616.5 & 2.701193448053943 & 1.7089231615691112 & 10383.0 & -6378.0 & Disp. 5 \\
            6 & 19928.0 & 332.1333333333333 & -147.0 & -10750.0 & 6613.483928825726 & 10212.0 &     -0.8404647945245984 & 0.23473423365399895 & 12077.0 & -10750.0 & Disp. 1 \\
            \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
            \bottomrule
        \end{tabular}
    }
    \caption{Datos estadísticos muestra paralela}
    \label{tab:stats_par}
\end{table}

La decisión de utilizar datos estadísticos como entrada es obtener una mayor cantidad de datos para los algoritmos de Machine Learning. Dada la naturaleza de este estudio, sólo se está teniendo en cuenta un valor, la desviación del reloj de cada dispositivo.

Obteniendo estas variables estadísticas es posible generar vectores mucho mayores que aportarán mayor información a los distintos algoritmos a la hora del aprendizaje.

\subsection{Reducción de la dimensionalidad}

En esta sección se buscarán valores estadísticos correlacionados entre sí. En caso de existir una correlación mayor a 0.9, se eliminarán esas variables antes de entrenar los modelos, puesto que no aportan información y provocarán que el algoritmo tarde aún más tiempo en ser entrenado.

La correlación entre las variables estadísticas se puede ver en la Fig. \ref{fig:corr}. Se puede ver como suma, media y mediana son las variables más correlacionadas entre sí, por tanto serán eliminadas 2 de ellas (en este caso, media y mediana).

\begin{figure}[htpb!]
    \centering
    \subfloat[Correlación entre las variables iniciales]{
        \includegraphics[scale=0.55]{../Python/plots/parallel/correlacion_stats.pdf}
    }
    \subfloat[Correlación entre las variables finales]{
        \includegraphics[scale=0.55]{../Python/plots/parallel/correlacion_stats_ftred.pdf}
    }
    \caption{Correlación entre las variables estadísticas}
    \label{fig:corr}
\end{figure} 

\section{Entrenamiento de los modelos}

En esta sección se mostrará el proceso de entrenamiento de los distintos modelos.

Para realizar estos entrenamientos se ha usado la librería \texttt{scikit-learn} sobre el lenguaje de programación Python. Esta librería tiene clases que implementan los algoritmos vistos anteriormente en la sección de \textit{Estado del arte}. Las clases que corresponden a cada modelo son las que se ven en la Tabla \ref{tab:equiv_models}.

\begin{table}[htpb!]
    \centering
    \resizebox{\textwidth}{!}{
    \begin{tabular}{cccC{0.2\textwidth}}
        \toprule
        Algoritmo & Implementación & Tipo de aprendizaje & Objetivo \\
        \midrule
        Árboles de decisión & \texttt{DecisionTreeClassifier} \cite{scikittrees} & Supervisado & Clasificación \\
        Random Forest & \texttt{RandomForestClassifier} \cite{scikitforest} & Supervisado & Clasificación \\
        MLP & \texttt{MLPClassifier} \cite{scikitmlp} & Supervisado & Clasificación \\
        Naive Bayes & \texttt{GaussianNB} \cite{scikitnaivebayes} & Supervisado & Clasificación \\
        KNN & \texttt{KNeighborsClassifier} \cite{scikitknn} & Supervisado & Clasificación \\
        SVM & \texttt{LinearSVC} \cite{scikitsvm} & Supervisado & Clasificación \\
        \addlinespace
        Isolation Forest & \texttt{IsolationForest} \cite{scikitisolation} & No supervisado & Detección de anomalías \\
        Local Outlier Factor & \texttt{LocalOutlierFactor} \cite{scikitlof} & No supervisado & Detección de anomalías \\
        OneClass-SVM & \texttt{OneClassSVM} \cite{scikitocsvm} & No supervisado & Detección de anomalías \\
        \bottomrule
    \end{tabular}}
    \caption{Equivalencia entre algoritmo e implementación}
    \label{tab:equiv_models}
\end{table}

\subsection{Entrenamiento de los algoritmos de clasificación}


A la hora de entrenar algoritmos de Machine Learning, lo primero que hay hacer es ajustar sus hiperparámetros. Los hiperparámetros de un modelo son parámetros del mismo que se pueden modificar para que este se adapte mejor a los datos con los que se está trabajando o para cambiar la forma en la aprende este modelo también para adaptarse a estos datos.

Para ajustar los hiperparámetros no se usa la completitud de los datos, se usa un modelo entrenamiento/validación/test. Los datos se han dividido en un conjunto de entrenamiento y otro de test, 70\% para entrenamiento y 30\% para test, lo habitual es tener en torno a una tercera parte de los datos para entrenamiento y el resto para test. Este proceso (Fig. \ref{fig:database}) se hace para comprobar la capacidad de generalización del modelo con datos que no haya visto nunca.

\begin{figure}[htpb!]
    \centering
    \resizebox{0.5\textwidth}{!}{
    \begin{tikzpicture}
        \node[database,label=below:Datos del dispositivo,database radius=1cm,database segment height=0.5cm] (data) {};
        \node (aux) [right = of data] {};
        \node[database,label=below:Entrenamiento,database radius=0.75cm,database segment height=0.375cm] (train) [above right = 2cm of aux] {};
        \node[database,label=below:Test,database radius=0.75cm,database segment height=0.375cm] (test) [below right = 2cm of aux] {};
        \node[database,label=below:{$\underset{\text{Reducido}}{\text{Entrenamiento}}$},database radius=0.5cm,database segment height=0.25cm] (train2) [right = 3cm of train] {};
        \node (aux2) [right = of train2] {};
        \node[database,label=below:Entrenamiento,label=right:70\%,database radius=0.5cm,database segment height=0.25cm] (train3) [above right = of aux2] {};
        \node[database,label=below:Validación,label=right:30\%,database radius=0.5cm,database segment height=0.25cm] (test) [below right = of aux2] {};
        \draw[-] (1.2,0) -- (aux.center);
        \draw[-] (aux.center) |- (3.4, 2.4) node [above, pos=0.75] {70\%};
        \draw[-] (aux.center) |- (3.4, -2.45) node [below, pos=0.75] {30\%};
        \draw[-] (5.5, 2.4) -- (8, 2.4) node [midway, above] {35\%};
        \draw[-] (9.5, 2.4) -- (aux2.center);
        \draw[-] (aux2.center) |- (11.3, 4.1);
        \draw[-] (aux2.center) |- (11.3, 0.66);
    \end{tikzpicture}
    }
    \caption{Particiones de los datos}
    \label{fig:database}
\end{figure}


Para particionar los datos se tomarán muestras aleatorias, pero ordenadas para mantener la correlación temporal de los datos. Por ejemplo, ante el conjunto de datos $x_1, \dots, x_{20}$, una muestra aleatoria podría ser $x_{15}, x_8, x_3, x_{17}, x_5, x_{12}$ pero si estos datos presentan una correlación temporal, como es el caso de este trabajo, esta se pierde. Por tanto, los datos han de ser devueltos a su orden natural $x_3, x_5, x_8, x_{12}, x_{15}, x_{17}$. 

El conjunto de entrenamiento se usará únicamente con el modelo final y con los hiperparámetros ya ajustados, puesto que contiene una gran cantidad de datos. Para ajustar los hiperparámetros de cada modelo y comparar los modelos entre sí se usará un conjunto reducido de este, un 35\% de los datos de entrenamiento.

Este subconjunto de los datos de entrenamiento también será dividido en un conjunto de entrenamiento/test, aunque en este caso el conjunto test recibirá el nombre de  conjunto de validación. Se entrenarán los distintos algoritmos con estos conjuntos con el fin de ajustar los hiperparámetros y decidir el mejor entre todos ellos.

Para comprobar qué hiperparámetros son los que mejor se ajustan a los datos, se usará la función \texttt{GridSearchCV} \cite{scikitgrid} que permite que dados un algoritmo y un conjunto de valores para los hiperparámetros probar todas las combinaciones y obtener así un accuracy de cada uno, con lo que se pueden comparar y filtrar únicamente a los mejores. Esta función permite usar la validación cruzada. La validación cruzada 

A continuación se mostrará un ejemplo del proceso de ajustar los hiperparámetros de un modelo, en este caso se usará el algoritmo de Random Forest sobre los datos la muestra paralela. Los hiperparámetros que se han decido ajustar son:
\begin{itemize}
    \item \texttt{criterion}: función que mide la pureza de los nodos hijos.
    \item \texttt{max\_features}: número de características que se tienen en cuenta para realizar la división de un nodo.
    \item \texttt{n\_estimators}: número de árboles de decisión que participan en el algoritmo.
\end{itemize}

Para evitar que una rama entre en un bucle infinito debido a que no es capaz de dividir correctamente los nodos se ha fijado la profundidad máxima de cada rama (hiperpárametro \texttt{max\_depth}) a un valor de 1000. 

Hablando en primer lugar sobre los hiperparámetros \texttt{criterion} y \texttt{max\_features} (Fig. \ref{fig:comp_hiperparam1}) se puede ver que en promedio el mejor valor de \texttt{criterion} es \texttt{gini}. Este parámetro será fijado y, a continuación, se comprobarán todos los pares de valores que generan los hiperparámetros \texttt{max\_features} y \texttt{n\_estimators} (Fig. \ref{fig:comp_hiperparam2}).

\begin{figure}[htpb!]
    \centering
    \subfloat[]{\includegraphics[width=0.45\textwidth]{../Python/plots/parallel/delta_random_forest_results}\label{fig:comp_hiperparam1}}
    \quad
    \subfloat[]{\includegraphics[width=0.45\textwidth]{../Python/plots/parallel/delta_random_forest_results2}\label{fig:comp_hiperparam2}}
    \caption{Comparativa hiperparámetros Random Forest}
    \label{fig:comp_hiperparam}
\end{figure}

Los mejores valores obtenidos son \texttt{criterion = gini}, \texttt{n\_estimators = 100} y \texttt{max\_feat ures = sqrt}. Con estos hiperparámetros se entrenará un modelo sobre el conjunto de entrenamiento menor y después se realizará una predicción con el conjunto de validación.


\subsection{Entrenamiento de los algoritmos de detección de anomalías}

A la hora de entrenar algoritmos de aprendizaje no supervisado, se realiza un proceso de ajuste similar al visto en la sección anterior. Sin embargo, existe una diferencia y esa son los datos de entrada del algoritmo.

Mientras que con los algoritmos de clasificación se realizaba una división únicamente teniendo en cuenta el tamaño del conjunto de los datos, en este caso se entrenará cada algoritmo únicamente con el 80\% de los datos de un dispositivo. Posteriormente, se usarán el 20\% de los datos de ese dispositivo para obtener una métrica y el 20\% de los datos del resto de dispositivos para otra. Este proceso se realiza con el fin de comprobar si el modelo es capaz de detectar como datos correctos aquellos provenientes de su mismo dispositivo y detectar como datos anómalos los del resto de dispositivos. Este división se puede ver de forma gráfica en la Fig. \ref{fig:unsupervised_database}.

\begin{figure}[htpb!]
    \centering
    \resizebox{0.5\textwidth}{!}{
    \begin{tikzpicture}    
        \node[database,label=below:Datos,database radius=1cm,database segment height=0.5cm, outer sep=0.5cm] (data) {};
        \node[database,label=below:$\underset{\text{Disp. }x}{\text{Datos}}$,database radius=0.75cm,database segment height=0.375cm, outer sep=0.3cm] (disp_data) [above right = 0cm and 2cm of data] {};
        \node[database,label=below:$\underset{\text{sin Disp. }x}{\text{Datos}}$,database radius=0.75cm,database segment height=0.375cm, outer sep=0.3cm] (disp_out_data) [below right = 0cm and 2cm of data] {};
        
        \node[database,label=below:Entrenamiento,database radius=0.75cm,database segment height=0.375cm, outer sep=0.3cm] (train) [above right = -0.5cm and 2cm of disp_data] {};
        \node[database,label=below:Test,database radius=0.75cm,database segment height=0.375cm, outer sep=0.3cm] (test) [below right = -1cm and 2cm of disp_data] {};
        
        
        \node (train2) [above right = -1cm and 2cm of disp_out_data] {\Huge\phantom{---}\xmark};
        \node[database,label=below:Test,database radius=0.75cm,database segment height=0.375cm, outer sep=0.3cm] (test2) [below right = -1cm and 2cm of disp_out_data] {};
        
        \draw[-] (data) -| (2.4,0) |- (disp_data);
        \draw[-] (data) -| (2.4,0) |- (disp_out_data);
        
        \draw[-] (disp_data) -| (6.4, 4) |- (train) node [above, pos=0.75] {80\%};
        \draw[-] (disp_data) -| (6.4, 4) |- (test) node [above, pos=0.75] {20\%};
        
        \draw[-] (disp_out_data) -| (6.4, -4) |- (train2) node [above, pos=0.75] {80\%};
        \draw[-] (disp_out_data) -| (6.4, -4) |- (test2) node [above, pos=0.75] {20\%};
        
    \end{tikzpicture}
    }
    \caption{Particiones de los datos}
    \label{fig:unsupervised_database}
\end{figure}

