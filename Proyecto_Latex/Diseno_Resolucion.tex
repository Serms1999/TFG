%!TEX root = TFG.tex

\chapter{Diseño y resolución} \label{chap:diseno}

En este capítulo se realiza la descripción de los experimentos realizados, su análisis y la búsqueda de un modelo de Machine Learning, así como los resultados finales del trabajo.

En este trabajo se usará una topología de red como la que ilustra la Fig. \ref{fig:top}. En dicha topología se puede ver que tenemos un observador (modelo RockPro64) y 5 dispositivos a analizar (Raspberry Pi 4 Model B).

\begin{figure}
    \centering
    \resizebox{0.5\textwidth}{!}{
        \input{topologia}
    }
    \caption{Topología de la red}
    \label{fig:top}
\end{figure}

La idea es mandar mensajes desde el observador a cada uno de los dispositivos y que cada uno de los dispositivos conteste a esos mensajes y obteniendo así una marca de tiempo de ese dispositivo.

\section{Elección del protocolo}

Las opciones barajadas han sido TCP e ICMP. En un principio se pensaba usar las marcas de tiempo contenidas en las cabeceras de estos protocolos, pero esta idea se descartó puesto que únicamente permitían obtener los tiempos en milisegundos. El objetivo era obtener los tiempos en nanosegundos por tanto, se enviaron los datos en el cuerpo del paquete que no tiene una limitación tan corta de espacio. 

Con el fin de mantener la conexión persistente en toda la muestra se escogió el protocolo TCP, ya que una vez establecida la conexión se mantendrá hasta el final.

\section{Obtención de datos}

Para obtener los datos se usará una estructura cliente-servidor. Los dispositivos a analizar serán los que tomen el rol de servidores y el observador será el cliente.

Con esta idea en mente se crea un programa servidor que escuche a cualquier dirección IP en un determinado puerto y responda con una marca de tiempo en nanosegundos. Este programa se ejecutará en cada uno de los dispositivos bajo análisis.

A la hora de capturar los datos se usó un reloj interno que no debería sufrir alteraciones que disminuyeran su valor (\texttt{steady\_clock}\cite{steadyclockcpp}).

Una vez los dispositivos estén todos escuchando, el observador ejecutará un programa cliente que es el que se encargará de enviar los mensajes al servidor correspondiente. Este programa guarda una marca de tiempo al comienzo de la ejecución $t_{start}$, que será nuestro punto de referencia. Después mandará $n$ mensajes equiespaciados en intervalos de 1 segundo.

En cada ejecución del bucle se obtendrá una marca de tiempo en el observador $t_i$, y una marca de tiempo del dispositivo $t'_i$. Con esto se consiguen tener varios datos:
\begin{itemize}
    \item La marca de tiempo relativa a cada mensaje desde el inicio, $t_i - t_{start}$. Teóricamente debería de dar valores exactos, ya que se manda un mensaje cada segundo, pero existe cierto retraso.
    \item La marca de tiempo absoluta del observador $t_i$.
    \item La marca de tiempo absoluta del dispositivo $t'_i$.
    \item La desviación del reloj del dispositivo respecto al del observador, $t_i - t'_i$.
\end{itemize}

Un ejemplo de como se guardan estos datos se puede ver en la Tabla \ref{tab:trace_example}.
\begin{table}
    \centering
    \resizebox{0.75\textwidth}{!}{
    \begin{tabular}{ccccc}
        \toprule
        \texttt{time} & \texttt{TSrock} & \texttt{TSrasp} & \texttt{offset} & \texttt{device} \\
        \midrule
        292 & 119238112796030 & 104592709716803 & -14645403079227 & 192.168.1.111 \\
        1001191222 & 119239113986960 & 104593710167425 & -14645403819535 & 192.168.1.111 \\
        2001485862 & 119240114281600 & 104594710453699 & -14645403827901 & 192.168.1.111 \\
        \vdots & \vdots & \vdots & \vdots & \vdots \\
        \bottomrule
    \end{tabular}
    }
    \caption{Ejemplo de los datos obtenidos de cada dispositivo}
    \label{tab:trace_example}
\end{table}

Este proceso se realizará para cada dispositivo tanto en una muestra secuencial, como en una muestra en paralelo.


\section{Análisis de los datos}

En esta sección se estudiará el incremento de la desviación del reloj en cada una de las muestras, así como la desviación acumulada en cada punto.

\subsection{Experimento 1: Muestra secuencial}

En este primer experimento se ha tomado una muestra de \SI{7200}{} segundos, es decir, \SI{2}{} horas por dispositivo, lo que en total suman \SI{10}{} horas de muestras.

En la Fig. \ref{fig:off_acu_secuencial} se muestra la desviación (offset) acumulada en cada dispositivo durante esas \SI{2}{} horas.

\begin{figure}
    \centering
    \includegraphics[scale=0.65]{../Python/plots/individual/offset_plot}
    \caption{Offset acumulado muestra secuencial}
    \label{fig:off_acu_secuencial}
\end{figure}

Como se puede ver hay 2 tipos de comportamiento. Los dispositivos 1, 2 y 3 se mantienen monótonos al comienzo para después incrementar mucho su desviación. Por contra los dispositivos 4 y 5 se mantienen sin grandes cambios en toda la muestra. Esto se puede ver más claramente en la Fig. \ref{fig:off_acu_secuencial_diffs}.

\begin{figure}
    \centering
    \subfloat[Dispositivos 1, 2 y 3]{\includegraphics[width=0.4\textwidth]{../Python/plots/individual/offset_plot_123}}
    \quad
    \subfloat[Dispositivos 4 y 5]{\includegraphics[width=0.4\textwidth]{../Python/plots/individual/offset_plot_45}}
    \caption{Diferencias entre offsets de dispositivos}
    \label{fig:off_acu_secuencial_diffs}
\end{figure}

Lo que interesa al final es obtener una forma de distinguir estadísticamente los datos, para ello se genera un gráfico que muestre entre que valores se mueven estos datos en cada dispositivo, en definitiva, se puede ver con un diagrama de cajas (Fig. \ref{fig:box_secuencial}). Se han eliminado los valores atípicos ya que a tan pequeña escala no dejan ver los verdaderos resultados.

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{../Python/plots/individual/boxplot_no_out}
    \caption{Diagrama de cajas muestra secuencial}
    \label{fig:box_secuencial}
\end{figure}

Este diagrama ilustra lo comentado anteriormente. Los dispositivos 4 y 5 son los que menos varían, esto se puede ver en que las cajas son pequeñas y la mediana está centrada entre los cuartiles (Q1 y Q3). 

En los otros 3 dispositivos se observa como entre la mediana y el tercer cuartil hay más espacio que entre la mediana y el primer cuartil. Esto se debe a que tienen muchos incrementos grandes, por eso crecen tan bruscamente.

Con esto se tiene una idea de los dispositivos son distinguibles estadísticamente, lo que confirma que se podrá entrenar un modelo que los identifique.

\iffalse
Por último se obtienen las variables estadísticas que podrán ser usadas para entrenar los modelos (Tabla \ref{tab:stats_sec}). 

\begin{table}
    \centering
    \resizebox{0.85\textwidth}{!}{
        \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c}
             & Sum & Mean & Median & Mode & Std & IQR & Kurtosis & Skew & Max & Min & Device \\
             \hline\hline
            1 & 161935.0 & 2698.9166666666665 & 2368.0 & -10638.0 & 4811.992019561929 & 4723.75 & 1.9261137847830017 & 0.393744697396757 & 16643.0 & -10638.0 & Disp. 1 \\
            2 & -133618.0 & -2226.9666666666667 & -2069.0 & -14962.0 & 4940.972387543091 & 3037.75 & 3.06918010272503 & 0.3990191392522864 & 12839.0 & -14962.0 & Disp. 2 \\
            3 & -474582.0 & -7909.7 & -8169.5 & -21129.0 & 4835.756096735922 & 4555.0 & 3.6509891533583105 & 0.7015937932968024 & 10047.0 & -21129.0 & Disp. 3 \\
            4 & 38723.0 & 645.3833333333333 & 343.5 & -511.0 & 2546.367949044463 & 2792.25 & 1.237821148508425 & 0.6920187401340381 & 8323.0 & -4649.0 & Disp. 4 \\
            5 & 18048.0 & 300.8 & 221.5 & -8231.0 & 3895.818561535789 & 4542.0 & 0.10736681592393049 & 0.13881288039853917 & 9109.0 & -8231.0 & Disp. 5 \\
            6 & 155944.0 & 2599.0666666666666 & 2368.0 & -10638.0 & 4960.2799021168785 & 4723.75 & 1.6897518199182318 & 0.28091999994143674 & 16643.0 & -10638.0 & Disp. 1 \\
            \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
        \end{tabular}
    }
    \caption{Datos estadísticos muestra secuencial}
    \label{tab:stats_sec}
\end{table}
\fi


\subsection{Experimento 2: Muestra paralela}

Para el segundo experimento se han capturado datos de todos los dispositivos simultáneamente durante un periodo de \SI{43200}{} segundos, es decir, \SI{12}{} horas.

La Fig. \ref{fig:off_acu_paralelo} muestra la desviación acumulada en cada dispositivo en este periodo de tiempo. En este gráfico también se han marcado ciertos puntos en los que los dispositivos parecen ``sincronizarse''. Con esto nos referimos a que alrededor de estas marcas de tiempo todos los dispositivos cambian de tendencia bruscamente y además parecen repetirse con cierta periodicidad. Las marcas de tiempo de este gráfico corresponden a los puntos $\{\SI{4000}{},  \SI{16500}{}, \SI{29000}{}, \SI{41000}{}\}$ que están aproximadamente equidistantes (aproximadamente \SI{12000}{} segundos).

\begin{figure}
    \centering
    \includegraphics[scale=0.65]{../Python/plots/parallel/offset_plot}
    \caption{Offset acumulado muestra paralela}
    \label{fig:off_acu_paralelo}
\end{figure}

Esta ``sincronización'' entre dispositivos parece deberse a algún tipo de actualización del reloj interno del dispositivo mediante algún demonio del sistema operativo. El principal demonio que se encarga de esta tarea es el servicio NTP, el cual fue desactivado para realizar estas pruebas. 

Consultando otro diagrama de cajas con el incremento de la desviación en cada instante (Fig. \ref{fig:box_paralelo}) se observa como todos los dispositivos están más a la par que en la muestra secuencial (Fig. \ref{fig:box_secuencial}). Aún así, siguen teniendo ciertas diferencias, con lo que se puede concluir que también son estadísticamente diferenciables.

\begin{figure}
    \centering
    \includegraphics[scale=0.7]{../Python/plots/parallel/boxplot_no_out}
    \caption{Diagrama de cajas muestra paralela}
    \label{fig:box_paralelo}
\end{figure}

\section{Elección de la muestra de datos}

Analizando los incrementos de la desviación en ambas muestras se puede ver que la muestra paralela tiene valores más parecidos a los esperados. Estos valores de incremento de la desviación son más pequeños y más parecidos entre todos los dispositivos, es por ello que se entrenarán los algoritmos con los datos de la muestra paralela.

Estos datos se obtendrán mediante una ventana deslizante de \SI{1}{} minuto sobre el incremento de la desviación del reloj del dispositivo. Se obtendrán las siguientes variables estadísticas:
\begin{multicols}{2}
    \begin{itemize}
        \item Suma
        \item Media
        \item Mediana
        \item Moda
        \item Desviación típica
        \item Rango intercuartílico
        \item Curtosis
        \item Coeficiente de asimetría (skewness)
        \item Máximo
        \item Mínimo
    \end{itemize}
\end{multicols}

Generando estos datos estadísticos de la muestra paralela mediante la ventana deslizante, se obtienen los resultados que se pueden ver en la Tabla \ref{tab:stats_par}. Estos datos estadísticos serán los que posteriormente se usarán para entrenar un modelo de Machine Learning.

\begin{table}
    \centering
    \resizebox{0.85\textwidth}{!}{
        \begin{tabular}{cccccccccccc}
            \toprule
             & Sum & Mean & Median & Mode & Std & IQR & Kurtosis & Skew & Max & Min & Device \\
            \midrule
            1 & 21773.0 & 362.8833333333333 & -306.5 & -17885.0 & 8212.584818005707 & 12095.5 & 0.0567239505757037 & 0.4351150677774124 & 20799.0 & -17885.0 & Disp. 1 \\
            2 & 4059.0 & 67.65 & 239.5 & -15862.0 & 5615.809629134339 & 3012.25 & 1.400480680742287 & -0.1242668154207108 & 14194.0 & -15862.0 & Disp. 2 \\
            3 & 1187.0 & 19.78333333333333 & 503.5 & -25009.0 & 7760.832728977938 & 8467.0 & 1.231550787741679 & -0.2621794660161829 & 20510.0 & -25009.0 & Disp. 3 \\
            4 & 74154.0 & 1235.9 & 2016.5 & -21616.0 & 8391.731753359314 & 9663.75 & 0.4104874852336051 & -0.4087239664161064 & 19992.0 & -21616.0 & Disp. 4 \\
            5 & -127078.0 & -2117.9666666666667 & -2385.0 & -11894.0 & 4354.015072678016 & 2737.0 & 1.9665757630194 & 0.6070065306393123 & 10383.0 & -11894.0 & Disp. 5 \\
            6 & 20147.0 & 335.78333333333336 & -306.5 & -17885.0 & 8244.497450208664 & 12095.5 & 0.0362682762350909 & 0.4263535051366743 & 20799.0 & -17885.0 & Disp. 1 \\
            \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
            \bottomrule
        \end{tabular}
    }
    \caption{Datos estadísticos muestra paralela}
    \label{tab:stats_par}
\end{table}

\section{Reducción de la dimensionalidad}

En esta sección buscaremos valores estadísticos correlacionados entre sí. En caso de existir habrá que eliminarlos antes de entrenar los modelos, puesto que no aportan información y provocarán que el algoritmo tarde aún más tiempo en ser entrenado.

La correlación entre las variables estadísticas se puede ver en la Fig. \ref{fig:corr}. Se puede ver como suma, media y mediana son las variables más correlacionadas entre sí, por tanto serán eliminadas 2 de ellas.

\begin{figure}
    \centering
    \subfloat[Correlación entre las variables iniciales]{
        \includegraphics[scale=0.55]{../Python/plots/parallel/correlacion_stats.pdf}
    }
    \subfloat[Correlación entre las variables finales]{
        \includegraphics[scale=0.55]{../Python/plots/parallel/correlacion_stats_ftred.pdf}
    }
    \caption{Correlación entre las variables estadísticas}
    \label{fig:corr}
\end{figure} 

\section{Entrenamiento de los modelos}

En esta sección se analizarán los resultados que hemos obtenido de los modelos sobre los datos de la muestra paralela, como hemos concluido en la sección anterior.

Para realizar este entrenamiento se ha usado la librería \texttt{scikit-learn} sobre el lenguaje de programación Python. Esta librería tiene clases que implementan los algoritmos vistos anteriormente que serán los que se usarán (Sec. \ref{sec:algorithms}). Las clases que corresponden a cada modelo son las que se ven en la Tabla \ref{tab:equiv_models}.

\begin{table}
    \centering
    \begin{tabular}{cc}
        \toprule
        Algoritmo & Implementación \\
        \midrule
        Árboles de decisión & \texttt{DecisionTreeClassifier} \cite{scikittrees} \\
        Random Forest & \texttt{RandomForestClassifier} \cite{scikitforest} \\
        MLP & \texttt{MLPClassifier} \cite{scikitmlp} \\
        Naive Bayes & \texttt{GaussianNB} \cite{scikitnaivebayes} \\
        KNN & \texttt{KNeighborsClassifier} \cite{scikitknn} \\
        SVM & \texttt{LinearSVC} \cite{scikitsvm} \\
        \bottomrule
    \end{tabular}
    \caption{Equivalencia entre algoritmo e implementación}
    \label{tab:equiv_models}
\end{table}

\begin{figure}
    \centering
    \resizebox{0.5\textwidth}{!}{
    \begin{tikzpicture}
        \node[database,label=below:Datos,database radius=1cm,database segment height=0.5cm] (data) {};
        \node (aux) [right = of data] {};
        \node[database,label=below:Entrenamiento,database radius=0.75cm,database segment height=0.375cm] (train) [above right = 2cm of aux] {};
        \node[database,label=below:Test,database radius=0.75cm,database segment height=0.375cm] (test) [below right = 2cm of aux] {};
        \node[database,label=below:{$\underset{\text{Reducido}}{\text{Entrenamiento}}$},database radius=0.5cm,database segment height=0.25cm] (train2) [right = 3cm of train] {};
        \node (aux2) [right = of train2] {};
        \node[database,label=below:Entrenamiento,label=right:70\%,database radius=0.5cm,database segment height=0.25cm] (train3) [above right = of aux2] {};
        \node[database,label=below:Validación,label=right:30\%,database radius=0.5cm,database segment height=0.25cm] (test) [below right = of aux2] {};
        \draw[-] (1.2,0) -- (aux.center);
        \draw[-] (aux.center) |- (3.4, 2.4) node [above, pos=0.75] {70\%};
        \draw[-] (aux.center) |- (3.4, -2.45) node [below, pos=0.75] {30\%};
        \draw[-] (5.5, 2.4) -- (8, 2.4) node [midway, above] {35\%};
        \draw[-] (9.5, 2.4) -- (aux2.center);
        \draw[-] (aux2.center) |- (11.3, 4.1);
        \draw[-] (aux2.center) |- (11.3, 0.66);
    \end{tikzpicture}
    }
    \caption{Particiones de los datos}
    \label{fig:database}
\end{figure}

A la hora de entrenar modelos de machine learning lo primero que hay hacer es ajustar sus hiperparámetros. Los hiperparámetros de un modelo son parámetros del mismo que se pueden modificar para que este se adapte mejor a los datos con los que se está trabajando o para cambiar la forma en la aprende este modelo también para adaptarse a estos datos.

Para ajustar los hiperparámetros no se usa la completitud de los datos, se usa un modelo entrenamiento/validación/test. Los datos se han dividido en un conjunto de entrenamiento y otro de test, 70\% para entrenamiento y 30\% para test, lo habitual es tener en torno a una tercera parte de los datos para entrenamiento y el resto para test. Este proceso (Fig. \ref{fig:database}) se hace para comprobar la capacidad de generalización del modelo con datos que no haya visto nunca.

Para particionar los datos se tomarán muestras aleatorias, pero ordenadas para mantener la correlación temporal de los datos. Por ejemplo, ante el conjunto de datos $x_1, \dots, x_{20}$, una muestra aleatoria podría ser $x_{15}, x_8, x_3, x_{17}, x_5, x_{12}$ pero si estos datos presentan una correlación temporal, como es el caso de este trabajo, esta se pierde. Por tanto, los datos han de ser devueltos a su orden natural $x_3, x_5, x_8, x_{12}, x_{15}, x_{17}$. 

El conjunto de entrenamiento se usará únicamente con el modelo final y con los hiperparámetros ya ajustados, puesto que contiene una gran cantidad de datos. Para ajustar los hiperparámetros de cada modelo y comparar los modelos entre sí se usará un conjunto reducido de este, un 35\% de los datos de entrenamiento.

Este subconjunto de los datos de entrenamiento también será dividido en un conjunto de entrenamiento/test, aunque en este caso el conjunto test recibirá el nombre de  conjunto de validación. Se entrenarán los distintos algoritmos con estos conjuntos con el fin de ajustar los hiperparámetros y decidir el mejor entre todos ellos.

Para comprobar qué hiperparámetros son los que mejor se ajustan a los datos, se usará la función \texttt{GridSearchCV} \cite{scikitgrid} que permite que dados un algoritmo y un conjunto de valores para los hiperparámetros probar todas las combinaciones y obtener así un accuracy de cada uno, con lo que se pueden comparar y filtrar únicamente a los mejores. Esta función permite usar la validación cruzada. La validación cruzada 

A continuación se mostrará un ejemplo del proceso de ajustar los hiperparámetros de un modelo, en este caso se usará el algoritmo de Random Forest sobre los datos la muestra paralela. Los hiperparámetros que se han decido ajustar son:
\begin{itemize}
    \item \texttt{criterion}: función que mide la pureza de los nodos hijos.
    \item \texttt{max\_features}: número de características que se tienen en cuenta para realizar la división de un nodo.
    \item \texttt{n\_estimators}: número de árboles de decisión que participan en el algoritmo.
\end{itemize}

Para evitar que una rama entre en un bucle infinito debido a que no es capaz de dividir correctamente los nodos se ha fijado la profundidad máxima de cada rama (hiperpárametro \texttt{max\_depth}) a un valor de 1000. 

Hablando en primer lugar sobre los hiperparámetros \texttt{criterion} y \texttt{max\_features} (Fig. \ref{fig:comp_hiperparam1}) se puede ver que en promedio el mejor valor de \texttt{criterion} es \texttt{gini}. Este parámetro será fijado y, a continuación, se comprobarán todos los pares de valores que generan los hiperparámetros \texttt{max\_features} y \texttt{n\_estimators} (Fig. \ref{fig:comp_hiperparam2}).

\begin{figure}
    \centering
    \subfloat[]{\includegraphics[width=0.45\textwidth]{../Python/plots/parallel/delta_random_forest_results}\label{fig:comp_hiperparam1}}
    \quad
    \subfloat[]{\includegraphics[width=0.45\textwidth]{../Python/plots/parallel/delta_random_forest_results2}\label{fig:comp_hiperparam2}}
    \caption{Comparativa hiperparámetros Random Forest}
    \label{fig:comp_hiperparam}
\end{figure}

Los mejores valores obtenidos son \texttt{criterion = gini}, \texttt{n\_estimators = 700} y \texttt{max\_features = sqrt}. Con estos hiperparámetros se entrenará un modelo sobre el conjunto de entrenamiento menor y después se realizará una predicción con el conjunto de validación.

