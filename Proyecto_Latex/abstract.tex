%!TEX root = TFG.tex

\chapter*{Extended abstract}
\addcontentsline{toc}{chapter}{Extended abstract} \label{chap:abstract}

Nowadays, the number of devices connected to the internet has increased significantly due to smartphones, IoT devices, autonomous cars, etc. These devices must be always connected to the internet to be able to perform the actions for which they are intended. 


These kinds of devices contain and share a lot of information about the people who use them. For this reason, many people try to get this data for purposes that may not be legal. One way to do it would be pretending that you are the device of the person that you want to access. In order to succeed, it is necessary to change all the identifiers to those that the criminal wants to impersonate. By doing this, people will connect to the criminal's device without being aware of it.


Devices that have the same hardware and software components are not exactly the same, there are some details during the manufacturing process that cannot be copied. Taking advantage of this, it will be created a system with the ability to identify those differences and as a consequence, between many devices.

In this article, IoT devices will be used to perform the objectives. These are devices capable of connecting to Internet, collect data and exchange this data in their own. The concept of IoT devices was proposed by Kevin Ashton in 1999.

This kind of device need a different network architecture than normal devices because of their requirements about security and quality of service (QoS). Different proposals have been given from multiple researchings. One of them is the one from Ibrar Yaqoob et al. \cite{yaqoob2017internet} where they propose a three layer architecture: application, transport, and sensing.

As mentioned, in this article it will be created a system that can identify those details mentioned above. Many studies have already researched device identification, but most of the time they focus on distinguishing devices, but these investigations do not bring the focus to these devices that are identical in both hardware and software.

The work developed by Pascal Oser et al. \cite{oser2018identifying} seeks to create a system that identifies devices among a total of 562 at the CERN research center. To execute it, they obtain the timestamps contained in the TCP header of the packets sent and received by these devices. Using these timestamps, they measure how often there is an overflow of the counter of this header and with it, they train a machine learning model capable of recognizing when each device does it.


Another example is the one developed by Salma Abdalla Hamad et al. \cite{hamad2019iot} in which a device authentication system is created for the purpose of giving access to a private network. These fingerprints are created considering several packet characteristics that were sent by the devices, such as packet length, destination IP, etc. By those features, devices can be classified as potential threats and not let them access the network. 

Another remarkable work is the one developed by Ahmet Aksoy et al. \cite{aksoy2019automated} which uses a genetic algorithm to obtain representative headers of the packet. Then, it is used different classification algorithms to first group them by brand and then identify them individually. 

Another approach to this kind of research is the one from Hossein Jafari et al. \cite{jafari2018iot} where they generate fingerprints of each device using radio frequencies. The process is done by obtaining samples of the SNR value in 5 different levels on each device. Then, they train three deep learning models in order to identify each one.

Another work is the one from Fabian Lance et al. \cite{lanze2012clock}, where they have designed a system which uses clock skew measurements to identify devices. The objetive in that research is to identify legitimate access points. They use the data saved by the NTP demon to approximate the clock skew.

Another important work is the one from Yair Meidan et al. \cite{meidan2017profiliot}. In this research they use wireless traffic traces to be capable of identify devices. They use a two layers system which firstly identify it the device is a IoT device or not. After this previous classification, they try to identify individual devices using Machine Learning algorithms.

Finally, the last work which has been analysed is the one from Loh Chin Choong Desmond et al. \cite{desmond2008identifying}. They use a concrete message in the wireless connection (probe request message) to generate a fingerprint from every device under analysis. Once they have all the data, they use an unsupervised Machine Learning algorithm called Maximum Variance Clustering to identify different devices.

In this research, to identify different devices, it will be used their absolute timestamps i.e. the time elapsed since 1$^\text{st}$ January, 1970. The small differences that distinguish these devices will make that as time progresses, their internal clocks will fluctuate. This error will be accumulated and it will become more noticeable each time.


From this point, the first step will be to calculate different statistical values of how this error changes over time in the different devices. After that, a machine learning algorithm will be trained, and it will be capable of performing this process automatically.


The test scenario made for this project consists of six IoT devices connected to a local network. One of them will act as a client and the other ve as servers. Every second the client will send a timestamp request to the servers, and they will reply with it. When the client receives this timestamp, it saves it as a record: “ (time from start), (absolute client time), (absolute server time), (time difference), (server ip)”. The client's time will be taken as a reference, and the differences will be analyzed between the other devices and the client.


The first problem appeared at this time. Taking into account that very small differences are going to been analyzed, the clock must have a great accuracy. Initially, it was thought that the best option was using the timestamps contained in the headers of the TCP and ICMP protocols. This idea was rejected since these headers have few bytes and with them it can only represent times in milliseconds, which does not provide enough information. For this reason, it was decided to use the body section of the packets in order to be able to send data of any length. In this case, it will send absolute timestamps in nanoseconds, which will be encoded with 64 bits. Finally, it was chosen the TCP protocol because in this way, it does not have to start a new connection with a device. 


These timestamps will be taken in two different ways. On the one hand, it will be taken a sequential sample and it will listen for 2 hours (7200 samples) on each device, one after another. This period of time represents a 10 hour sample (36000 samples). On the contrary, it will carry out a parallel sample of all the devices for 12 hours (43200 samples per device) Another issue that has arised in this point is that the device's internal clock is altered by other processes, such as the NTP protocol. As a result, it is necessary to use an internal clock that does not decrease its value (\texttt{steady\_clock}). 


The next step is set on to the data analysis part. Firstly, it be will obtained the increase in the deviation between each sample of a device. Due to these increases, it will be generated a boxplot of each sample (sequential and parallel), in which each box will represent one of the devices under analysis. These graphs correspond to Fig. \ref{fig:box_secuencial} and Fig. \ref{fig:box_paralelo}. In these graphs, since it is being worked with such small values, the outliers hide completely the results it is necessary to see, so they will not be shown. 


The median is expected to be approximately 0 and the interquartile range is expected to be very similar on each device. These results are expected since it is being analyzed clonic devices and they do not suffer from clock skew, at least theoretically.


Looking both graphs, it will be observed that the median is actually close to 0, but both the interquartile range and the non-outliers values range oscillate much more in the sequential 8 sample. Therefore, from this point on and because of the training of the models that perform the identification process, This sample will not be taken into account; the focus will be laid on the parallel sample.

Once it is decided which data is going to be used it is necessary to identify anomalous values between the correct ones. To do that it will be used an anomaly detection algorithm called IsolationForest. This algorithm requieres a parameter which approximate the value of anomalous values, for example, in this research, it has been concluded that this value is near 5\%. This value was obtained trying different values and looking into the graphs that shows the values which are going to be removed from the dataset.


At this point the statistical values are obtained, it is going to be used a 1 minute sliding window (60 samples) to obtain them. The statistical values that will be obtained will be: sum, mean, median, mode, standard deviation, interquartile range, kurtosis, skewness, maximum and minimum.


Before training the models, it is going to be checked if there is a correlation between the different statistical values, since having correlated data does not provide information. To do it, a correlation matrix between all the statistical variables is generated and those variables that have a high correlation value with another variable are eliminated. In order to train the different models, it is going to be used the \texttt{scikit-learn} library for Python, along with utilities such as \texttt{numpy} and \texttt{pandas}. In this work it will be used supervised learning algorithms, and those that are going to be used are: Decision Trees, Random Forest, Multilayer Perceptron (MLP), Naive Bayes, K Nearest Neighbours (KNN) and Support Vector Machines (SVM).

 In order to train different models and obtain the best possible results, it must be set their hyperparameters. To make this adjustment, it will be used a smaller set of data, but it must be representative of the totality of the data since each training costs a considerable amount of time. It is going to be used a training/validation/test model.


the set of all the data will be divided into two, one with \SI{70}{\percent} of the data and another with \SI{30}{\percent}. The training set will be used to train the final model and the test model will be used to see the generalization capacity of the model.


To obtain the final model it is pivotal to choose the algorithm and hyperparameters that give the best results according to the data. To get it, each algorithm must be adjusted to obtain its best results and with them decide which algorithm to use.


The process of adjusting an algorithm takes time since each algorithm have to be trained with each combination of hyperparameters that is required for being tested. For this reason, the volume of data will be reduced (\SI{70}{\percent} of the total) and it will be keet only \SI{35}{\percent} of it. This subset will also be divided into a 70/30 ratio in order to validate the results of training with data that the model has not seen before.


To make these partitions, random samples are taken, but as the data had temporal correlation, it is needed to reorder them so that this correlation can be kept and the models are able to recognize it. 


To adjust the hyperparameters of an algorithm, an object called grid, which allows to specify all the hyperparameter that will be tested, is going to be used. This tool is very useful since it automates the whole process of testing different hyperparameters and allows us to obtain, in a single run, the results of an algorithm with each combination of hyperparameters.


Once all the models have been adjusted, it is easy to see that the ones with the best accuracies are those that are based on trees; both decision trees and random forest. In particular random forest is the one that gives us the best results, so, this random forest algorithm will be chosen to be trained as the final model. 


Finally, the random forest algorithm with its custom hyperparameters and the training set in its completeness is the only one that have to be trained. Once this has been done, its ability to generalize is checked with the test set and it is obtained a final accuracy of \SI{99.13}{\percent}. 


It can be concluded that it is possible to identify theoretically identical devices automatically, but it should be noted that all of this process has been made on a private network. If the same study had been done over the Internet, the result would have been different. This is because even if all the devices were on the same local network and only the observer was out, each timestamp of each device could be routed differently, which would cause measurement errors. A possible solution to this problem would be to take much longer samples in time, since statistically the packets between two devices will be routed most of the time along the same path, leaving those who are not as outliers. 

On the other side of the argument, the graph of the deviation was expected to be linear, but this is not the case even if a clock that doesn't decrease its value is being used and the NTP service has been disabled.

