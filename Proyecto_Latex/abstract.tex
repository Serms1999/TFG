%!TEX root = TFG.tex

\chapter*{Extended abstract}
\addcontentsline{toc}{chapter}{Extended abstract} \label{chap:abstract}

Nowadays, the number of devices connected to the internet has increased significantly due to smartphones, IoT devices, autonomous cars, etc. These devices must be always connected to the internet to be able to perform the actions for which they are intended. 

These kinds of devices contain and share a lot of information about the people who use them. For this reason, many people try to get this data for purposes that may not be legal. One way to do it would be to pretend that you are the device of the person that you want to access. In order to succeed, it is necessary to change all the identifiers to those that the criminal wants to impersonate. By doing this, people will connect to the criminal's device without being aware of it.


Devices that have the same hardware and software components are not exactly the same, there are some details during the manufacturing process that cannot be copied. Taking advantage of this, a system with the ability to identify those differences was created and as a consequence, between many devices too.

In this work, \acrfull{iot} devices were used to perform the objectives. These are devices capable of connecting to the Internet, collecting data and exchanging this data on their own. The concept of IoT devices was proposed by Kevin Ashton in 1999.

These types of devices need a different network architecture than normal devices because of their requirements regarding security and \acrfull{qos}. Different proposals have been given from multiple research. One of them is the one from Ibrar Yaqoob et al. \cite{yaqoob2017internet} where they propose a three-layer architecture: application, transport, and sensing.

As mentioned, in this work a system that can identify those details mentioned above was created. Many studies have already researched device identification, but a lot of times they focus on distinguishing devices, but these investigations do not bring the focus to these devices that are identical in both hardware and software.

Most of the read approaches use Machine Learning, specifically supervised learning algorithms, to identify between different devices, and they use this capacity to identify devices for security purposes, for example, giving access to a private network or knowing if an access point may be malicious. The results of the read approaches are situated between 42\% and nearly 100\% of accuracy value. 

In this research, to identify different devices, several timestamps were taken from every device under analysis and, after that, their differences from one to the next one were calculated. These timestamps contain the amount of time since the device was turned on. The small differences that distinguish these devices make that as time goes by, their internal clocks fluctuated. This error accumulated over time and became more noticeable.

To achieve this work's objectives an architecture for how this work is developed was proposed. This architecture can be divided into two parts. On the one hand, there are devices that generate all the data and share it. On the other hand, there is an external device whose purpose is to collect the data received from the other devices, analyse and process it as well as adjust the Machine Learning algorithms that have been used. This external device also evaluates the Machine Learning models that have been trained yet and additionally it compares them too. This architecture performs all the following stages:

\begin{enumerate}[label=\Alph*)]
    \item \textbf{Set up stability conditions}. This stage performs one fundamental thing which is preparing all devices that are going to be tested. The devices' internal clocks have been set to a fixed frequency. In addition, the \acrshort{ntp} service has to be disabled. 
    \item \textbf{Data gathering}. In this stage, every second, each device under analysis generates a timestamp from its internal clock and sends it to the external device. This stage repeats for the established time, which is a period long enough. 
    \item \textbf{Data analysis and processing}. In this stage, the external device receives all the timestamps from the devices under analysis and it calculates the increase between every two consecutive timestamps. With all these timestamps' increasing values a dataset is built by the external device. Using this dataset, and a sliding window, various statistical values are obtained which are representative of the window in question. Some of these statistical value may be correlated, that's why those which are correlated are going to be removed from the dataset, except one of them which act as a representative value.
    \item \textbf{Model generation}. In this stage the different Machine Learning algorithms are selected. In this work supervised learning algorithms for classification are used as well as unsupervised learning anomaly detection algorithms. Once all the algorithms are selected, it is needed to adjust their hyperparameters in order to make the resulting models fit the data of this work in the best possible way.
    \item \textbf{Model evaluation}. In this last stage, all the metrics, which are going to be used to compare the different models with each other, are selected. Classification algorithms and anomaly detection algorithms do not use the same metrics to be compared. The resulting metrics are obtained from each trained model and then all these models are compared between them.
\end{enumerate}


The test scenario made for this project consists of six \acrshort{iot} devices connected to a local network. One of them acted as a client and the others acted as servers. Every second the client sent a timestamp request to the servers, and they replied with it. When the client received this timestamp, it saved it as a record: ``(time from the start), (client's ignition time), (server's ignition time), (time difference), (server IP)''. The client's time was taken as a reference, and the differences were analysed between the other devices and the client.


The first problem appeared at this time. Taking into account that very small differences were analysed, they might have great accuracy of the times. Initially, it was thought that the best option was using the timestamps contained in the headers of the TCP and ICMP protocols. This idea was discarded since these headers have few bytes and with them, it can only represent times in milliseconds, which does not provide enough information. For this reason, it was decided to use the body section of the packets; to be able to send data of any length. In this case, it will send absolute timestamps in nanoseconds, which will be encoded with 64 bits. Finally, it was chosen the TCP protocol because, in this way, it was not necessary to start a new connection every time a timestamp was sent.


These timestamps were taken in two different ways. On the one hand, a sequential sample was taken in which it was listening for 2 hours (7200 samples) on each device, one after another. This period of time represents a 10 hours sample (36000 samples). On the other hand, a parallel sample of all devices was also carried out, and this one developed 12 hours (with 43200 samples per device). Another issue that arose at this point was that the device's internal clock was altered by other time synchronization processes, such as the NTP protocol. As a result, it was necessary to use an internal clock that changes its value in a linear way. (\texttt{steady\_clock}). This internal clock contains the number of CPU cycles since the device was switched on.

The next step was set on to the data analysis part. Firstly, the increase in the deviation between each sample of a device was obtained. In those graphs, the median was expected to be approximately 0 and the interquartile range was expected to be very similar on each device. These results were expected since identical devices are being analyzed and they do not suffer from clock skew, at least theoretically.

Looking at both graphs, the one from the sequential sample and the one from the parallel sample, the median was observed to be actually close to 0, however, the interquartile range oscillated much more in the sequential sample. Therefore, from this point on and because of the training of the models that perform the identification process, this sample was not taken into account; the focus was laid on the parallel sample.

Once it was decided which data was going to be used, the statistical values were obtained, and a 1-minute sliding window (60 samples) was used to obtain them. The statistical values that were obtained were: sum, mean, median, mode, standard deviation, interquartile range, kurtosis, skewness, maximum and minimum.

Before training the models, it was checked if there was a correlation between the different statistical values since having correlated data does not provide information. To do that, a correlation matrix between all the statistical variables was generated and those variables that have a high correlation value with another variable were eliminated. In order to train the different models, it was used the \texttt{scikit-learn} library for Python, along with utilities such as \texttt{numpy} and \texttt{pandas}. In this work it was used supervised learning algorithms, such as Decision Trees, Random Forest, \acrfull{mlp}, Naive Bayes, \acrfull{knn} and \acrfull{svm}. In addition, it was also used unsupervised learning anomaly detection algorithms, such as Isolation Forest, \acrfull{lof} and \acrfull{ocsvm}.

In order to train the different supervised algorithms and obtain the best possible results, their hyperparameters must be set. To make this adjustment, it was used a smaller set of data, but it was representative of the totality of the data since each training costs a considerable amount of time. It was used a training/validation/test model.
 
 
The set of all the data will be divided into two, one with \SI{70}{\percent} of the data and another with \SI{30}{\percent}. The training set will be used to train the final model and the test model will be used to see the generalization capacity of the model.


The process of adjusting an algorithm takes time since each algorithm has to be trained with each combination of hyperparameters that are required for being tested. For this reason, the volume of data was reduced (\SI{70}{\percent} of the total) and kept only \SI{35}{\percent} of it. This subset will also be divided into a 70/30 ratio in order to validate the results of training with data that the model had not seen before.

To make these partitions, random samples were taken, but as the data had temporal correlation, reordering them was needed so that this correlation could be kept and the models were able to recognize it. 

To adjust the hyperparameters of an algorithm, an object called grid, which allows specifying all the hyperparameters that were tested, was used. This tool is very useful since it automates the whole process of testing different hyperparameters and allows us to obtain, in a single run, the results of an algorithm with each combination of hyperparameters.

As regards anomaly detection algorithms, another scheme was used. Their hyperparameters were also adjusted similarly to the supervised ones, however, anomaly detection algorithms used only the data from one device to be trained. It was used \SI{80}{\percent} of the data from every device to train the algorithm and, after that, the algorithm was evaluated using two different tests, the remaining \SI{20}{\percent} of the device data and the \SI{20}{\percent} of all the remaining devices' data. Looking at the first test, how capable to detect the current device was shown, and with the second one, it was shown how capable of not making a mistake was the algorithm.


Once all the models had been tested, it could be seen that the ones with the best results were those that are based on trees; both Decision Trees and Random Forest.  In particular, Random Forest was the one with the best results, so, this Random Forest algorithm was chosen to be trained as the final model. 

Finally, the Random Forest algorithm with its custom hyperparameters and the training set in its completeness was the only one that have to be trained. Once this has been done, its ability to generalize is checked with the test set and it is obtained a final accuracy of \SI{99.38}{\percent}, a recall of \SI{99.39}{\percent} and an $f-score$ of \SI{99.38}{\percent}.


It can be concluded that it is possible to identify theoretically identical devices automatically, but it should be noted that all of this process has been made on a private network. If the same study had been done over the Internet, the result would have been different. This is because even if all the devices were on the same local network and only the observer was out, each timestamp of each device could be routed differently, which would cause measurement errors. A possible solution to this problem would be to take much longer samples in time, since statistically the packets between two devices will be routed most of the time along the same path, leaving those which are not, like outliers. 

