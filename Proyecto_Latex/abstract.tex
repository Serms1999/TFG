%!TEX root = TFG.tex

\chapter*{Extended abstract}
\addcontentsline{toc}{chapter}{Extended abstract} \label{chap:abstract}

Nowadays, the number of devices connected to the internet has increased significantly due to smartphones, IoT devices, autonomous cars, etc. These devices must be always connected to the internet to be able to perform the actions for which they are intended. 

These kinds of devices contain and share a lot of information about the people who use them. For this reason, many people try to get this data for purposes that may not be legal. One way to do it would be to pretend that you are the device of the person that you want to access. In order to succeed, it is necessary to change all the identifiers to those that the criminal wants to impersonate. By doing this, people will connect to the criminal's device without being aware of it.


Devices that have the same hardware and software components are not exactly the same, there are some details during the manufacturing process that cannot be copied. Taking advantage of this, a system with the ability to identify those differences was created and as a consequence, between many devices.

In this work, \acrfull{iot} devices were used to perform the objectives. These are devices capable of connecting to the Internet, collecting data and exchanging this data on their own. The concept of IoT devices was proposed by Kevin Ashton in 1999.

These types of devices a different network architecture than normal devices because of their requirements regarding security and \acrfull{qos}. Different proposals have been given from multiple research. One of them is the one from Ibrar Yaqoob et al. \cite{yaqoob2017internet} where they propose a three-layer architecture: application, transport, and sensing.

As mentioned, in this work a system that can identify those details mentioned above was created. Many studies have already researched device identification, but a lot of times they focus on distinguishing devices, but these investigations do not bring the focus to these devices that are identical in both hardware and software.

The work developed by Pascal Oser et al. \cite{oser2018identifying} seeks to create a system that identifies devices among a total of 562 at the CERN research centre. To execute it, they obtain the timestamps contained in the TCP header of the packets sent and received by these devices. Using these timestamps, they measure how often there is an overflow of the counter of this header and with it, they train a machine learning model capable of recognizing when each device does it.


Another example is the one developed by Salma Abdalla Hamad et al. \cite{hamad2019iot} in which a device authentication system is created for the purpose of giving access to a private network. These fingerprints are created considering several packet characteristics that were sent by the devices, such as packet length, destination IP, etc. By those features, devices can be classified as potential threats and not let access the network. 

Another remarkable work is the one developed by Ahmet Aksoy et al. \cite{aksoy2019automated} which uses a genetic algorithm to obtain representative headers of the packet. Then, it is used different classification algorithms to first group them by brand and then identify them individually. 

Another approach to this kind of research is the one from Hossein Jafari et al. \cite{jafari2018iot} where they generate fingerprints of each device using radio frequencies. The process is done by obtaining samples of the SNR value at 5 different levels on each device. Then, they train three deep learning models in order to identify each one.

Another work is the one from Fabian Lance et al. \cite{lanze2012clock}, where they have designed a system which uses clock skew measurements to identify devices. The objective of that research is to identify legitimate access points. They use the data saved by the NTP demon to approximate the clock skew.

Another important work is the one from Yair Meidan et al. \cite{meidan2017profiliot}. In this research, they use wireless traffic traces to be capable of identifying devices. They use a two layers system which firstly identifies it the device is an \acrshort{iot} device or not. After this previous classification, they try to identify individual devices using Machine Learning algorithms.

Finally, the last work which has been analysed is the one from Loh Chin Choong Desmond et al. \cite{desmond2008identifying}. They use a concrete message in the wireless connection (probe request message) to generate a fingerprint from every device under analysis. Once they have all the data, they use an unsupervised Machine Learning algorithm called Maximum Variance Clustering to identify different devices.

In this research, to identify different devices, several timestamps were taken from every device under analysis and, after that, their differences from one to the next one were calculated. These timestamps contain the amount of time since the device was turned on. The small differences that distinguish these devices will make that as time progresses, their internal clocks will fluctuate. This error will be accumulated and it will become more noticeable each time.

The test scenario made for this project consists of six \acrshort{iot} devices connected to a local network. One of them acted as a client and the others acted as servers. Every second the client sent a timestamp request to the servers, and they replied with it. When the client received this timestamp, it saved it as a record: ``(time from the start), (client's ignition time), (server's ignition time), (time difference), (server IP)''. The client's time was taken as a reference, and the differences were analysed between the other devices and the client.


The first problem appeared at this time. Taking into account that very small differences were analysed, they might have great accuracy of the times. Initially, it was thought that the best option was using the timestamps contained in the headers of the TCP and ICMP protocols. This idea was discarded since these headers have few bytes and with them, it can only represent times in milliseconds, which does not provide enough information. For this reason, it was decided to use the body section of the packets; to be able to send data of any length. In this case, it will send absolute timestamps in nanoseconds, which will be encoded with 64 bits. Finally, it was chosen the TCP protocol because, in this way, it was not necessary to start a new connection every time a timestamp was sent.


These timestamps were taken in two different ways. On the one hand, a sequential sample was taken in which it was listening for 2 hours (7200 samples) on each device, one after another. This period of time represents a 10 hours sample (36000 samples). On the other hand, a parallel sample of all devices was also carried out, and this one developed 12 hours (with 43200 samples per device). Another issue that arose at this point was that the device's internal clock was altered by other time synchronization processes, such as the NTP protocol. As a result, it was necessary to use an internal clock that changes its value in a linear way. (\texttt{steady\_clock}). This internal clock contains the number of CPU cycles since the device was switched on.

The next step was set on to the data analysis part. Firstly, the increase in the deviation between each sample of a device was obtained. In those graphs, the median was expected to be approximately 0 and the interquartile range was expected to be very similar on each device. These results were expected since identical devices are being analyzed and they do not suffer from clock skew, at least theoretically.

Looking at both graphs, the one from the sequential sample and the one from the parallel sample, the median was observed to be actually close to 0, however, the interquartile range oscillated much more in the sequential sample. Therefore, from this point on and because of the training of the models that perform the identification process, this sample was not taken into account; the focus was laid on the parallel sample.

Once it was decided which data was going to be used, the statistical values were obtained, and a 1-minute sliding window (60 samples) was used to obtain them. The statistical values that were obtained were: sum, mean, median, mode, standard deviation, interquartile range, kurtosis, skewness, maximum and minimum.

Before training the models, it was checked if there was a correlation between the different statistical values since having correlated data does not provide information. To do that, a correlation matrix between all the statistical variables was generated and those variables that have a high correlation value with another variable were eliminated. In order to train the different models, it was used the \texttt{scikit-learn} library for Python, along with utilities such as \texttt{numpy} and \texttt{pandas}. In this work it was used supervised learning algorithms, such as Decision Trees, Random Forest, \acrfull{mlp}, Naive Bayes, \acrfull{knn} and \acrfull{svm}. In addition, it was also used unsupervised learning anomaly detection algorithms, such as Isolation Forest, \acrfull{lof} and \acrfull{ocsvm}.

In order to train the different supervised algorithms and obtain the best possible results, their hyperparameters must be set. To make this adjustment, it was used a smaller set of data, but it was representative of the totality of the data since each training costs a considerable amount of time. It was used a training/validation/test model.
 
 
The set of all the data will be divided into two, one with \SI{70}{\percent} of the data and another with \SI{30}{\percent}. The training set will be used to train the final model and the test model will be used to see the generalization capacity of the model.


The process of adjusting an algorithm takes time since each algorithm has to be trained with each combination of hyperparameters that are required for being tested. For this reason, the volume of data was reduced (\SI{70}{\percent} of the total) and kept only \SI{35}{\percent} of it. This subset will also be divided into a 70/30 ratio in order to validate the results of training with data that the model had not seen before.

To make these partitions, random samples were taken, but as the data had temporal correlation, reordering them was needed so that this correlation could be kept and the models were able to recognize it. 

To adjust the hyperparameters of an algorithm, an object called grid, which allows specifying all the hyperparameters that were tested, was used. This tool is very useful since it automates the whole process of testing different hyperparameters and allows us to obtain, in a single run, the results of an algorithm with each combination of hyperparameters.

As regards anomaly detection algorithms, another scheme was used. Their hyperparameters were also adjusted similarly to the supervised ones, however, anomaly detection algorithms used only the data from one device to be trained. It was used \SI{80}{\percent} of the data from every device to train the algorithm and, after that, the algorithm was evaluated using two different tests, the remaining \SI{20}{\percent} of the device data and the \SI{20}{\percent} of all the remaining devices' data. Looking at the first test, how capable to detect the current device was shown, and with the second one, it was shown how capable of not making a mistake was the algorithm.


Once all the models had been tested, it was easy to see that the ones with the best results were those that are based on trees; both Decision Trees and Random Forest.  In particular, Random Forest was the one with the best results, so, this Random Forest algorithm was chosen to be trained as the final model. 

Finally, the Random Forest algorithm with its custom hyperparameters and the training set in its completeness was the only one that have to be trained. Once this has been done, its ability to generalize is checked with the test set and it is obtained a final accuracy of \SI{99.38}{\percent}, a recall of \SI{99.39}{\percent} and an $f-score$ of \SI{99.38}{\percent}.


It can be concluded that it is possible to identify theoretically identical devices automatically, but it should be noted that all of this process has been made on a private network. If the same study had been done over the Internet, the result would have been different. This is because even if all the devices were on the same local network and only the observer was out, each timestamp of each device could be routed differently, which would cause measurement errors. A possible solution to this problem would be to take much longer samples in time, since statistically the packets between two devices will be routed most of the time along the same path, leaving those who are not, like outliers. 

