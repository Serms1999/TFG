%!TEX root = TFG.tex

\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen} \label{chap:resumen}

En este proyecto se ha diseñado una solución capaz de identificar dispositivos conectados en red local en base a las diferencias entre sus relojes internos comparados con un reloj que se fija como referencia. Con esto, ha sido creado un mecanismo que permitirá gestionar de una mejor manera los dispositivos autorizados a realizar ciertas funciones o estar conectados con otros dispositivos de la red.

Este trabajo se puede dividir en cuatro partes. En primer lugar se realiza una fase de diseño de la arquitectura de la solución que se propone. En esta propuesta de solución se identifican las etapas requeridas para llevar a cabo el desarrollo de este proyecto. En la siguiente parte se explica la obtención de los datos, para lo que han sido utilizados 5 dispositivos iguales en hardware y software (Raspberry Pi 4 Model B). De estos dispositivos se obtienen marcas de tiempo cada segundo de dos formas distintas. Por otro lado, se tiene la fase de análisis estadístico de los datos obtenidos, en el que se generan nuevos datos a partir de los previos. Por último, está la fase del desarrollo de un modelo de Machine Learning que sea capaz de automatizar todo el proceso de distinguir los dispositivos partiendo de los datos estadísticos que se han obtenido previamente.

Para obtener los datos se ha hecho uso de una arquitectura cliente-servidor entre los dispositivos a analizar y el dispositivo observador, con el fin de controlar el ritmo de envío de los paquetes. Las capturas se han realizado de dos formas, en secuencial y en paralelo. Secuencialmente hace referencia a que primero se obtienen todas las marcas de tiempo de un dispositivo y posteriormente se analiza el siguiente. Por otro lado, paralelamente hace referencia a que se obtienen marcas de tiempo de todos los dispositivos simultáneamente.

Una vez se tienen todas las marcas de tiempo, se obtienen sus desviaciones respecto al dispositivo que se designó como referencia. De estas desviaciones se obtiene su incremento entre cada dos puntos. Comparando las muestras individual y paralela entre sí mediante gráficos de cajas, se aprecia que los datos de la muestra individual presentan una estructura que no se asemeja tanto a los datos esperados de estos experimentos. Lo esperado sería encontrar la desviación con valores centrados en 0 (lo que se da en ambas muestras) y muy similares entre todos los dispositivos. Es en este último requisito que la muestra individual no se comporta de la forma esperada y, por tanto, a partir de este punto sólo se usarán los datos de la muestra paralela. Estos valores son agrupados mediante una ventana deslizante de 1 minuto, que equivale a 60 paquetes (se toman muestras cada segundo), y de cada uno de estos grupos se obtienen diversas variables estadísticas.

Antes de proceder con la sección dedicada a Machine Learning, se deben eliminar las variables estadísticas que presenten correlación, de esta forma se reduce la cantidad de variables que se usarán para los entrenamientos.

Una vez se tienen las variables estadísticas finales, se analizarán los algoritmos de Machine Learning que han sido escogidos para este trabajo. Los algoritmos que se van a analizar son por una parte de clasificación, como Random Forest, \acrfull{mlp}, \acrfull{knn}, Naive Bayes, Árboles de decisión y \acrfull{svm} con kernel lineal; y por otra, de detección de anomalías no supervisados como, Isolation Forest, \acrfull{lof} y \acrfull{ocsvm}.

Para comparar los modelos de clasificación entre sí se usará el modelo entrenamiento/validación/test como forma de dividir los datos. Se entrenarán todos los modelos con el conjunto de entrenamiento y se comprobará su capacidad de generalización con el conjunto de validación. A la hora de entrenar los modelos se comprobarán diferentes parrillas de hiperparámetros para ajustar los modelos lo más posible a los datos de entrenamiento.

A la hora de particionar el conjunto de datos de cara a los entrenamientos de los algoritmos se ha seguido un método propio, con el fin de no perder la correlación temporal que presenta la muestra. Para dividir el conjunto se selecciona una muestra aleatoria de los datos del tamaño deseado, y posteriormente se restablece el orden original de los mismos. De esta forma se consigue reducir el tamaño del conjunto de datos y conservar la correlación temporal de mismos.

Por otra parte, los algoritmos de detección de anomalías han sido entrenados por cada dispositivo, en lugar de todos a la vez. Se ha usado una parte de los datos de cada dispositivo para entrenar el algoritmo, y posteriormente se ha evaluado su rendimiento el resto de los datos de ese dispositivo y con el resto de dispositivos, esto último de forma separada.

Al realizar estos entrenamientos se puede apreciar que los modelos basados en árboles son los mejores, tanto árboles de decisión (95.92\%) como Random Forest (99.22\%). Finalmente se elige el algoritmo de Random Forest y se procede a entrenarlo con la totalidad de los datos de entrenamiento y los hiperparámetros usados anteriormente. 

Al realizar estos entrenamientos se ha apreciado que los algoritmos de detección de anomalías no obtienen resultados elevados. Por contra, algunos de los algoritmos de clasificación sí que son capaces de obtenerlos, en concreto, los basados en árboles (Árboles de decisión y Random Forest). Este último es el algoritmo elegido para generar un modelo de identificación final.

Como resultado se tiene que este último modelo de Random Forest final obtiene un valor final de Accuracy de 99.38\%, de Recall de 99.39\% y de $f$-score de 99.38\%. Gracias a este resultado, se ha llegado a la conclusión de que es posible automatizar el proceso de distinguir dispositivos idénticos de forma remota.

Con vistas a futuro, se puede concluir que este trabajo aporta una solución que potencialmente puede ayudar a la lucha contra la ciberdelicuencia, pero se deben resolver algunos inconvenientes. Por un lado, hay servicios que modifican constantemente el reloj del sistema y esto dificulta la tarea de crear una huella para los dispositivos. Por otro lado, y tal vez el más importante, es que esta huella ha de ser creada para cada dispositivo concreto, lo cual es una labor incomensurable.

